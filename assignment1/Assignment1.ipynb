{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from multiprocessing import Pool, Lock\n",
    "import psutil\n",
    "\n",
    "mp_lock = Lock()\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "data_dir = 'ml-1m'\n",
    "\n",
    "movies_filename = 'movies.dat'\n",
    "users_filename = 'users.dat'\n",
    "ratings_filename = 'ratings.dat'\n",
    "\n",
    "movies_columns = ['MovieID', 'Title', 'Genres']\n",
    "users_columns = ['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']\n",
    "ratings_columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "\n",
    "def make_dataframe(data_dir, filename, columns):\n",
    "    data_file = os.path.join(data_dir, filename)\n",
    "    return pd.read_csv(data_file, delimiter='::', names=columns, encoding='latin-1', engine='python')\n",
    "\n",
    "movies = make_dataframe(data_dir, movies_filename, movies_columns)\n",
    "users = make_dataframe(data_dir, users_filename, users_columns)\n",
    "ratings = make_dataframe(data_dir, ratings_filename, ratings_columns)\n",
    "data = (users, movies, ratings)\n",
    "\n",
    "def measure_memory():\n",
    "    time.sleep(2)\n",
    "    mem = process.memory_info().rss\n",
    "    print('Memory usage: ', mem / 1000000, ' MB')\n",
    "    time.sleep(2)\n",
    "\n",
    "def rmse(errors):\n",
    "    return np.mean(errors**2)**(1/2)\n",
    "\n",
    "def mae(errors):\n",
    "    return np.mean(np.abs(errors))\n",
    "\n",
    "def rating_errors(test_set, model):\n",
    "    errors = test_set['Rating'] - test_set.apply(model, axis=1)\n",
    "    return rmse(errors), mae(errors)\n",
    "\n",
    "def crop_ratings(arr, min_lim, max_lim):\n",
    "    new_arr = np.where(arr > max_lim, max_lim, arr)\n",
    "    new_arr = np.where(new_arr < min_lim, min_lim, arr)\n",
    "    return new_arr\n",
    "\n",
    "def make_indices_with_holes(movie_ids):\n",
    "    \"\"\"\n",
    "    We want for each movie the corresponding index of the column in the matrix M, \n",
    "    just like we want for each user the corresponding index of the row in the matrix U.\n",
    "    For the users this is straightforward, since the the user ID's are integers from 1 \n",
    "    to the number of users and we can just subtract 1 to get all the indices. For some \n",
    "    reason, some integers are skipped in the movie ID's, so we cannot use them directly \n",
    "    as indices for the M matrix. \n",
    "    \n",
    "    For example: there is no movie with ID '91', so we want the movie with ID '92' \n",
    "    to correspond to M column index of 90 (remember that the first movie ID is '1' which \n",
    "    corresponds to M column index 0)\n",
    "    \n",
    "    Therefore we make an indices array with holes, which has parts like \n",
    "    [0, 1, ..., 218, 0, 219, 220, 221, ...]. The IDs '91' and '221' are missing. So a movie \n",
    "    with ID '222' will then take the 221st element of this array, which will take the value\n",
    "    219 for the M column index, because 2 zeros are inserted for the missing IDs.\n",
    "    \"\"\"\n",
    "    indices_with_holes = np.array([], dtype=np.int32)\n",
    "    skipped_integers = 0\n",
    "    for i in np.arange(len(movie_ids)):\n",
    "        if movie_ids[i] == i + 1 + skipped_integers:\n",
    "            indices_with_holes = np.append(indices_with_holes, i)\n",
    "        else:\n",
    "            while movie_ids[i] != i + 1 + skipped_integers:\n",
    "                indices_with_holes = np.append(indices_with_holes, 0)\n",
    "                skipped_integers += 1\n",
    "            indices_with_holes = np.append(indices_with_holes, i)\n",
    "    return indices_with_holes\n",
    "\n",
    "\n",
    "def make_movie_column_indices(train_set, movie_ids):\n",
    "    train_set_movie_ids = train_set['MovieID'].values - 1\n",
    "    indices_with_holes = make_indices_with_holes(movie_ids)\n",
    "    movie_column_indices = indices_with_holes[train_set_movie_ids]\n",
    "    return movie_column_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_model_fold_error(train_index, test_index, model_type, model_specific_params):\n",
    "    train_set = ratings.iloc[train_index]\n",
    "    test_set = ratings.iloc[test_index]\n",
    "\n",
    "    mean_rating = train_set['Rating'].mean()\n",
    "\n",
    "    model = make_naive_model(mean_rating, train_set, model_type, model_specific_params)\n",
    "\n",
    "    rms_error, ma_error = rating_errors(test_set, model)\n",
    "    \n",
    "    mp_lock.acquire()\n",
    "    print('rmse ', rms_error, ' mae ', ma_error)\n",
    "    mp_lock.release()\n",
    "    \n",
    "    measure_memory()\n",
    "    \n",
    "    return rms_error, ma_error\n",
    "\n",
    "def test_naive_model(data, model_type, folds=5):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=folds, random_state=42, shuffle=True)\n",
    "    \n",
    "    if model_type == '1':\n",
    "        model_specific_params = {}\n",
    "    elif model_type == '2':\n",
    "        model_specific_params = {'user_indices': users['UserID']}\n",
    "    elif model_type == '3':\n",
    "        model_specific_params = {'movie_ids': movies['MovieID']}\n",
    "        model_specific_params.update({'indices_with_holes': \n",
    "                                      make_indices_with_holes(model_specific_params['movie_ids'])})\n",
    "    else:\n",
    "        return ValueError(f'Model type {model_type} is unknown.')\n",
    "    \n",
    "    params = [(train_index, \n",
    "               test_index, \n",
    "               model_type,\n",
    "               model_specific_params) for train_index, test_index in cv.split(ratings)]\n",
    "    pool = Pool(5)\n",
    "    fold_errors = pool.starmap(naive_model_fold_error, params)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    rms_errors = np.array([])\n",
    "    ma_errors = np.array([])\n",
    "    \n",
    "    for errors in fold_errors:\n",
    "        rms_errors = np.append(rms_errors, errors[0])\n",
    "        ma_errors = np.append(ma_errors, errors[1])\n",
    "        \n",
    "    mean_rms_error = np.mean(rms_errors)\n",
    "    mean_ma_error = np.mean(ma_errors)\n",
    "\n",
    "    print('mean rms error', mean_rms_error)\n",
    "    print('mean ma error', mean_ma_error)\n",
    "    \n",
    "def make_naive_model(mean_rating, train_set, model_type, model_specific_params):\n",
    "    if model_type == '1':\n",
    "        def model(row):\n",
    "            return mean_rating\n",
    "        return model\n",
    "    elif model_type == '2':\n",
    "        mean_rating_per_user = np.array([])\n",
    "        \n",
    "        for user_index in model_specific_params['user_indices']:\n",
    "            subset = train_set[train_set['UserID'].values == user_index]\n",
    "            mean_rating_per_user = np.append(mean_rating_per_user, np.mean(subset['Rating']))\n",
    "\n",
    "        mean_rating_per_user = np.where(np.isnan(mean_rating_per_user), mean_rating, mean_rating_per_user)\n",
    "\n",
    "        def model(row):\n",
    "            user_id = row['UserID'] - 1\n",
    "            return mean_rating_per_user[user_id]\n",
    "        return model\n",
    "    elif model_type == '3':\n",
    "        mean_rating_per_movie = np.array([])\n",
    "        \n",
    "        for movie_index in model_specific_params['movie_ids']:\n",
    "            subset = train_set[train_set['MovieID'].values == movie_index]\n",
    "            mean_rating_per_movie = np.append(mean_rating_per_movie, np.mean(subset['Rating']))\n",
    "\n",
    "        mean_rating_per_movie = np.where(np.isnan(mean_rating_per_movie), mean_rating, mean_rating_per_movie)\n",
    "\n",
    "        def model(row):\n",
    "            movie_id = row['MovieID'] - 1\n",
    "            return mean_rating_per_movie[model_specific_params['indices_with_holes'][movie_id]]\n",
    "        return model\n",
    "    else:\n",
    "        return ValueError(f'Model type {model_type} is unknown.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "test_naive_model(data, model_type='1')\n",
    "\n",
    "duration = time.time() - t0 - 4\n",
    "print('Run time: ', duration, ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "test_naive_model(data, model_type='2')\n",
    "\n",
    "duration = time.time() - t0 - 4\n",
    "print('Run time: ', duration, ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "test_naive_model(data, model_type='3')\n",
    "\n",
    "duration = time.time() - t0 - 4\n",
    "print('Run time: ', duration, ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall mean rating \n",
    "mean_rating = ratings['Rating'].mean()\n",
    "\n",
    "# Lookup tables for naive models 2, 3, 4 and 5\n",
    "mean_rating_per_user = {user_id : ratings[ratings['UserID'] == user_id]['Rating'].mean() for user_id in users['UserID']}\n",
    "mean_rating_per_movie = {movie_id : ratings[ratings['MovieID'] == movie_id]['Rating'].mean() for movie_id in movies['MovieID']}\n",
    "\n",
    "def test_error_4_5(test_set,reg):\n",
    "    \n",
    "    mean_rating_per_movie_list = np.array([mean_rating_per_movie[movie_id] for movie_id in test_set['MovieID']])\n",
    "    mean_rating_per_user_list = np.array([mean_rating_per_user[user_id] for user_id in test_set['UserID']])\n",
    "    \n",
    "    ##the predicted rating value for the test set using model 4 and 5.\n",
    "    mean_rating_list = np.vstack((mean_rating_per_movie_list,mean_rating_per_user_list)).T\n",
    "    pre_rating = reg.predict(mean_rating_list)[0]\n",
    "    \n",
    "    rating_error = ((test_set['Rating'] - pre_rating)**2).mean()**(1/2)\n",
    "    \n",
    "    return rating_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_4_5(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors_4 = np.array([])\n",
    "    rating_errors_5 = np.array([])\n",
    "    \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        user_ids = train_set['UserID']\n",
    "        \n",
    "        mean_rating_per_movie = {movie_id : train_set[train_set['MovieID'] == movie_id]['Rating'].mean() for movie_id in movies['MovieID']}\n",
    "        mean_rating_per_user = {user_id : train_set[train_set['UserID'] == user_id]['Rating'].mean() for user_id in users['UserID']}\n",
    "        \n",
    "        \n",
    "        ##the lists of mean Ritem and mean Ruser for each rating in the train_set\n",
    "        mean_rating_per_movie_list = np.array([mean_rating_per_movie[movie_id] for movie_id in train_set['MovieID']])\n",
    "        mean_rating_per_user_list = np.array([mean_rating_per_user[user_id] for user_id in train_set['UserID']])\n",
    "        \n",
    "        ## stack the Ritem and Ruser lists for linear fitting\n",
    "        mean_rating_list = np.vstack((mean_rating_per_movie_list, mean_rating_per_user_list)).T\n",
    "        \n",
    "        ## uisng Ordinary least squares Linear Regression to find alpha beta and gamma\n",
    "        reg_4 = LinearRegression(fit_intercept=False).fit(mean_rating_list, train_set['Rating'])\n",
    "        reg_5 = LinearRegression(fit_intercept=True).fit(mean_rating_list, train_set['Rating'])\n",
    "\n",
    "        \n",
    "        rating_err_4 = test_error_4_5(test_set,reg_4)\n",
    "        rating_err_5 = test_error_4_5(test_set,reg_5)\n",
    "        \n",
    "        rating_errors_4 = np.append(rating_errors_4,rating_err_4)\n",
    "        rating_errors_5 = np.append(rating_errors_5,rating_err_5)\n",
    "        \n",
    "        print('Rating Error for Naive Model 4:', rating_err_4)\n",
    "        print('Rating Error for Naive Model 5:', rating_err_5)\n",
    "    \n",
    "    print('Mean Rating Error for Naive Model 4:', np.mean(rating_errors_4))   \n",
    "    print('Mean Rating Error for Naive Model 5:', np.mean(rating_errors_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_naive_model_4_5(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_fold_error(train_index, test_index, user, movies, factors, n_training_steps, lr, lam):\n",
    "    n_users = len(users)\n",
    "    n_movies = len(movies)\n",
    "    \n",
    "    U = np.random.normal(0.0, 1.0, ((n_users, factors)))\n",
    "    M = np.random.normal(0.0, 1.0, ((factors, n_movies)))\n",
    "    \n",
    "    train_set = ratings.iloc[train_index]\n",
    "    test_set = ratings.iloc[test_index]\n",
    "\n",
    "    train_user_indices = train_set['UserID'].values - 1\n",
    "    test_user_indices = test_set['UserID'].values - 1\n",
    "\n",
    "    movie_ids = movies['MovieID'].values\n",
    "    train_movie_indices = make_movie_column_indices(train_set, movie_ids)\n",
    "    test_movie_indices = make_movie_column_indices(test_set, movie_ids)\n",
    "    \n",
    "    train_set_rating_matrix = np.zeros((n_users, n_movies))\n",
    "    for u, m, rating in zip(train_user_indices, train_movie_indices, train_set['Rating']):\n",
    "        train_set_rating_matrix[u, m] = rating\n",
    "\n",
    "    train_rmses = np.array([])\n",
    "    test_rmses = np.array([])\n",
    "\n",
    "    train_maes = np.array([])\n",
    "    test_maes = np.array([])\n",
    "\n",
    "    for step in range(n_training_steps):\n",
    "        predicted_ratings = np.dot(U, M)\n",
    "\n",
    "        train_set_predicted_ratings = predicted_ratings[train_user_indices, train_movie_indices]\n",
    "        test_set_predicted_ratings = predicted_ratings[test_user_indices, test_movie_indices]\n",
    "\n",
    "        train_errors = train_set['Rating'] - crop_ratings(train_set_predicted_ratings, 1.0, 5.0)\n",
    "        test_errors = test_set['Rating'] - crop_ratings(test_set_predicted_ratings, 1.0, 5.0)\n",
    "        \n",
    "        train_rmse, test_rmse = rmse(train_errors), rmse(test_errors)\n",
    "        \n",
    "        train_rmses = np.append(train_rmses, train_rmse)\n",
    "        test_rmses = np.append(test_rmses, test_rmse)\n",
    "\n",
    "        train_maes = np.append(train_maes, mae(train_errors))\n",
    "        test_maes = np.append(test_maes, mae(test_errors))\n",
    "\n",
    "        mp_lock.acquire()\n",
    "        print('step ', step, ' rmse train ', train_rmse, ' rmse test ', test_rmse)\n",
    "        mp_lock.release()\n",
    "        \n",
    "        for u, m in zip(train_user_indices, train_movie_indices):\n",
    "            error = train_set_rating_matrix[u, m] - np.dot(U[u, :], M[:, m])\n",
    "            U[u, :] += lr * (2 * error * M[:, m] - lam * U[u, :])\n",
    "            M[:, m] += lr * (2 * error * U[u, :] - lam * M[:, m])\n",
    "        \n",
    "        if step == n_training_steps - 1:\n",
    "            measure_memory()\n",
    "    \n",
    "    return train_rmses, test_rmses, train_maes, test_maes\n",
    "\n",
    "\n",
    "def matrix_factorization(data, factors, lr, n_training_steps, lam, n_folds):\n",
    "    users, movies, ratings = data\n",
    "\n",
    "    rating_errors = np.array([])\n",
    "\n",
    "    cv = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "\n",
    "    print('Initialize...')\n",
    "\n",
    "    params = [(train_index, \n",
    "               test_index, \n",
    "               users, \n",
    "               movies, \n",
    "               factors, \n",
    "               n_training_steps, \n",
    "               lr, \n",
    "               lam) for train_index, test_index in cv.split(ratings)]\n",
    "    pool = Pool(5)\n",
    "    fold_errors = pool.starmap(mf_fold_error, params)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    train_rmses_per_fold = np.array([])\n",
    "    test_rmses_per_fold = np.array([])\n",
    "\n",
    "    train_maes_per_fold = np.array([])\n",
    "    test_maes_per_fold = np.array([])\n",
    "    \n",
    "    for errors in fold_errors:\n",
    "        train_rmses, test_rmses, train_maes, test_maes = errors\n",
    "        train_rmses_per_fold = np.append(train_rmses_per_fold, train_rmses)\n",
    "        test_rmses_per_fold = np.append(test_rmses_per_fold, test_rmses)\n",
    "        train_maes_per_fold = np.append(train_maes_per_fold, train_maes)\n",
    "        test_maes_per_fold = np.append(test_maes_per_fold, test_maes)\n",
    "    \n",
    "    return np.stack((train_rmses_per_fold, \n",
    "                     test_rmses_per_fold, \n",
    "                     train_maes_per_fold, \n",
    "                     test_maes_per_fold))\n",
    "\n",
    "number_of_folds = 5\n",
    "number_of_training_steps = 75\n",
    "number_of_factors = 10\n",
    "learning_rate = 0.005\n",
    "regularization = 0.05\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "errors = matrix_factorization(data,\n",
    "                              factors=number_of_factors,\n",
    "                              lr=learning_rate,\n",
    "                              n_training_steps=number_of_training_steps,\n",
    "                              lam=regularization,\n",
    "                              n_folds=number_of_folds)\n",
    "\n",
    "duration = time.time() - t0 - 4\n",
    "\n",
    "print('Run time: ', duration, ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_rmses = np.mean(np.reshape(errors[0], (number_of_folds, number_of_training_steps)), axis=0)\n",
    "mean_test_rmses = np.mean(np.reshape(errors[1], (number_of_folds, number_of_training_steps)), axis=0)\n",
    "mean_train_maes = np.mean(np.reshape(errors[2], (number_of_folds, number_of_training_steps)), axis=0)\n",
    "mean_test_maes = np.mean(np.reshape(errors[3], (number_of_folds, number_of_training_steps)), axis=0)\n",
    "\n",
    "training_steps = np.arange(number_of_training_steps)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.plot(training_steps, mean_train_rmses, label='train rmse')\n",
    "ax.plot(training_steps, mean_test_rmses, label='test rmse')\n",
    "ax.plot(training_steps, mean_train_maes, label='train mae')\n",
    "ax.plot(training_steps, mean_test_maes, label='test mae')\n",
    "ax.set_title('Matrix factorization errors')\n",
    "ax.set_xlabel('training step')\n",
    "ax.set_ylabel('error')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
