{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12810c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'ml-1m'\n",
    "\n",
    "movies_filename = 'movies.dat'\n",
    "users_filename = 'users.dat'\n",
    "ratings_filename = 'ratings.dat'\n",
    "\n",
    "movies_columns = ['MovieID', 'Title', 'Genres']\n",
    "users_columns = ['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']\n",
    "ratings_columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "\n",
    "def create_dataframe(data_dir, filename, columns):\n",
    "    data_file = os.path.join(data_dir, filename)\n",
    "    return pd.read_csv(data_file, delimiter='::', names=columns, encoding='latin-1', engine='python')\n",
    "\n",
    "movies = create_dataframe(data_dir, movies_filename, movies_columns)\n",
    "users = create_dataframe(data_dir, users_filename, users_columns)\n",
    "ratings = create_dataframe(data_dir, ratings_filename, ratings_columns)\n",
    "data = (users, movies, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d0150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_error(test_set, model, subset:int=None):\n",
    "    if subset is not None:\n",
    "        actual_ratings = test_set[:subset]['Rating']\n",
    "        predicted_ratings = test_set[:subset].apply(model, axis=1)\n",
    "    else:\n",
    "        actual_ratings = test_set['Rating']\n",
    "        predicted_ratings = test_set.apply(model, axis=1)\n",
    "\n",
    "    rating_error = ((actual_ratings - predicted_ratings)**2).mean()**(1/2)\n",
    "    return rating_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall mean rating \n",
    "mean_rating = ratings['Rating'].mean()\n",
    "\n",
    "# Lookup tables for naive models 2, 3, 4 and 5\n",
    "mean_rating_per_user = {user_id : ratings[ratings['UserID'] == user_id]['Rating'].mean() for user_id in users['UserID']}\n",
    "mean_rating_per_movie = {movie_id : ratings[ratings['MovieID'] == movie_id]['Rating'].mean() for movie_id in movies['MovieID']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af559708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_1(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors = np.array([])\n",
    "        \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        mean_rating = train_set['Rating'].mean()\n",
    "        \n",
    "        def model(row):\n",
    "            return mean_rating\n",
    "        \n",
    "        rating_err = rating_error(test_set, model, subset)\n",
    "        print(rating_err)\n",
    "        \n",
    "        rating_errors = np.append(rating_errors, rating_err)\n",
    "    return rating_errors\n",
    "\n",
    "errors = test_naive_model_1(data)\n",
    "mean_error = np.mean(errors)\n",
    "print('mean error', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_2(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors = np.array([])\n",
    "        \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        user_ids = train_set['UserID']\n",
    "        mean_rating_per_user = {user_id : train_set[train_set['UserID'] == user_id]['Rating'].mean() for user_id in users['UserID']}\n",
    "        \n",
    "        def model(row):\n",
    "            user_id = row['UserID']\n",
    "            return mean_rating_per_user[user_id]\n",
    "        \n",
    "        rating_err = rating_error(test_set, model, subset)\n",
    "        print(rating_err)\n",
    "        \n",
    "        rating_errors = np.append(rating_errors, rating_err)\n",
    "    return rating_errors\n",
    "\n",
    "errors = test_naive_model_3(data)\n",
    "mean_error = np.mean(errors)\n",
    "print('mean error', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_3(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors = np.array([])\n",
    "        \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        movie_ids = train_set['MovieID']\n",
    "        mean_rating_per_movie = {movie_id : train_set[train_set['MovieID'] == movie_id]['Rating'].mean() for movie_id in movies['MovieID']}\n",
    "        \n",
    "        def model(row):\n",
    "            movie_id = row['MovieID']\n",
    "            return mean_rating_per_movie[movie_id]\n",
    "        \n",
    "        rating_err = rating_error(test_set, model, subset)\n",
    "        print(rating_err)\n",
    "        \n",
    "        rating_errors = np.append(rating_errors, rating_err)\n",
    "    return rating_errors\n",
    "\n",
    "errors = test_naive_model_2(data)\n",
    "mean_error = np.mean(errors)\n",
    "print('mean error', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b856dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_error_4_5(test_set,reg):\n",
    "    \n",
    "    mean_rating_per_movie_list = np.array([mean_rating_per_movie[movie_id] for movie_id in test_set['MovieID']])\n",
    "    mean_rating_per_user_list = np.array([mean_rating_per_user[user_id] for user_id in test_set['UserID']])\n",
    "    \n",
    "    ##the predicted rating value for the test set using model 4 and 5.\n",
    "    mean_rating_list = np.vstack((mean_rating_per_movie_list,mean_rating_per_user_list)).T\n",
    "    pre_rating = reg.predict(mean_rating_list)[0]\n",
    "    \n",
    "    rating_error = ((test_set['Rating'] - pre_rating)**2).mean()**(1/2)\n",
    "    \n",
    "    return rating_error\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_4_5(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors_4 = np.array([])\n",
    "    rating_errors_5 = np.array([])\n",
    "    \n",
    "        \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        user_ids = train_set['UserID']\n",
    "        \n",
    "        mean_rating_per_movie = {movie_id : train_set[train_set['MovieID'] == movie_id]['Rating'].mean() for movie_id in movies['MovieID']}\n",
    "        mean_rating_per_user = {user_id : train_set[train_set['UserID'] == user_id]['Rating'].mean() for user_id in users['UserID']}\n",
    "        \n",
    "        \n",
    "        ##the lists of mean Ritem and mean Ruser for each rating in the train_set\n",
    "        mean_rating_per_movie_list = np.array([mean_rating_per_movie[movie_id] for movie_id in train_set['MovieID']])\n",
    "        mean_rating_per_user_list = np.array([mean_rating_per_user[user_id] for user_id in train_set['UserID']])\n",
    "        \n",
    "        ## stack the Ritem and Ruser lists for linear fitting\n",
    "        mean_rating_list = np.vstack((mean_rating_per_movie_list, mean_rating_per_user_list)).T\n",
    "        \n",
    "        print(mean_rating_list)\n",
    "        \n",
    "        ## uisng Ordinary least squares Linear Regression to find alpha beta and gamma\n",
    "        reg_4 = LinearRegression(fit_intercept=False).fit(mean_rating_list, train_set['Rating'])\n",
    "        reg_5 = LinearRegression(fit_intercept=True).fit(mean_rating_list, train_set['Rating'])\n",
    "\n",
    "        \n",
    "        rating_err_4 = test_error_4_5(test_set,reg_4)\n",
    "        rating_err_5 = test_error_4_5(test_set,reg_5)\n",
    "        \n",
    "        rating_errors_4 = np.append(rating_errors_4,rating_err_4)\n",
    "        rating_errors_5 = np.append(rating_errors_5,rating_err_5)\n",
    "        \n",
    "        print('Rating Error for Naive Model 4:', rating_err_4)\n",
    "        print('Rating Error for Naive Model 5:', rating_err_5)\n",
    "    \n",
    "    print('Mean Rating Error for Naive Model 4:', np.mean(rating_errors_4))   \n",
    "    print('Mean Rating Error for Naive Model 5:', np.mean(rating_errors_5))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_naive_model_4_5(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65910252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matrix_factorization(data, subset:int=None):\n",
    "    factors = 10\n",
    "    learning_rate = 0.0001\n",
    "    n_training_steps = 75\n",
    "    lam = 0.001\n",
    "    \n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    n_users = len(users)\n",
    "    n_movies = len(movies)\n",
    "    \n",
    "    rating_errors = np.array([])\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    indices = np.arange(1, n_movies + 1)\n",
    "    movie_ids = movies['MovieID'].values\n",
    "    shifted_indices = np.array([], dtype=np.int32)\n",
    "    counter = 0\n",
    "    for i in indices:\n",
    "        if movie_ids[i - 1] == i + counter:\n",
    "            shifted_indices = np.append(shifted_indices, i - 1)\n",
    "        else:\n",
    "            shifted_indices = np.append(shifted_indices, 0)\n",
    "            shifted_indices = np.append(shifted_indices, i - 1)\n",
    "            counter += 1\n",
    "            \n",
    "    print('Initialize...')\n",
    "    \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        U = np.random.normal(0, 1, (n_users, factors))\n",
    "        M = np.random.normal(0, 1, (factors, n_movies))\n",
    "\n",
    "        predicted_ratings = np.matmul(U, M)\n",
    "\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        \n",
    "        user_indices = train_set['UserID'].values - 1\n",
    "        movie_indices = train_set['MovieID'].values - 1\n",
    "        \n",
    "        movie_indices = shifted_indices[movie_indices]\n",
    "                \n",
    "        print('\\nStart training')\n",
    "        \n",
    "        for step in range(n_training_steps):\n",
    "            train_set_predicted_ratings = predicted_ratings[user_indices, movie_indices]\n",
    "            rating_errs = (train_set['Rating'] - train_set_predicted_ratings)\n",
    "            \n",
    "            print(len(rating_errs))\n",
    "            \n",
    "            for u, m, err in zip(user_indices, movie_indices, rating_errs):\n",
    "                old_U = U[u, :]\n",
    "                U[u, :] += learning_rate * (2 * err * M[:, m] - lam * old_U)\n",
    "                M[:, m] += learning_rate * (2 * err * old_U - lam * M[:, m])\n",
    "            \n",
    "            predicted_ratings = np.matmul(U, M)\n",
    "            print('step ', step, ' error ', np.mean(rating_errs**2)**(1/2))\n",
    "        \n",
    "        test_set_predicted_ratings = predicted_ratings[user_indices, movie_indices]\n",
    "        test_rmse = ((test_set['Rating'] - test_set_predicted_ratings)**2).mean()**(1/2)\n",
    "\n",
    "        print('test error ', test_rmse)\n",
    "        \n",
    "        rating_errors = np.append(rating_errors, test_rmse)\n",
    "    return rating_errors\n",
    "\n",
    "errors = test_matrix_factorization(data)\n",
    "mean_error = np.mean(errors)\n",
    "print('mean error', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8925fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "\n",
    "c = np.vstack((a,b)).T\n",
    "\n",
    "print(c[0, 1])\n",
    "\n",
    "c[1][0] += 1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reg_4.coef_, reg_4.intercept_)\n",
    "# print(reg_5.coef_, reg_5.intercept_)\n",
    "\n",
    "# fig = plt.figure(figsize = (8, 8))\n",
    "# ax = plt.axes(projection =\"3d\")\n",
    "# ax.scatter3D(mean_rating_per_movie_list, train_set['Rating'], mean_rating_per_user_list, c=train_set['Rating'], s=0.01)\n",
    "# x = np.linspace(3.0, 4.0, 100)\n",
    "# y = np.linspace(0.0, 5.0, 10)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "# ax.scatter3D(X, Y, reg_4.coef_[0] * X + reg_4.coef_[1] * Y + reg_4.intercept_, s=0.1)\n",
    "# ax.scatter3D(X, Y, reg_5.coef_[1] * X + reg_5.coef_[0] * Y + reg_5.intercept_, s=1.0)\n",
    "# ax.view_init(0, -190)\n",
    "# plt.show()\n",
    "\n",
    "# x = np.linspace(0.0, 5.0, 100)\n",
    "# e = np.random.normal(0, 0.5, 100)\n",
    "# y = 0.7 * x - 0.3\n",
    "\n",
    "x = np.array([])\n",
    "y = np.array([])\n",
    "\n",
    "for i in np.arange(5):\n",
    "    x = np.concatenate((x, np.random.normal(1.0 + i * 0.5, 1.0, 100)))\n",
    "    y = np.concatenate((y, i * np.ones(100)))\n",
    "\n",
    "lin_reg = LinearRegression(fit_intercept=True).fit(x[..., None], y)\n",
    "\n",
    "a = lin_reg.coef_[0]\n",
    "b = lin_reg.intercept_\n",
    "\n",
    "print(lin_reg.coef_)\n",
    "print(lin_reg.intercept_)\n",
    "print(lin_reg.score(x[..., None], y))\n",
    "\n",
    "plt.plot(np.linspace(0, 5, 100), a * np.linspace(0, 5, 100) + b)\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
