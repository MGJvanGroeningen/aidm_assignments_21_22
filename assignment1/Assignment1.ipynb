{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49cbd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12810c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'ml-1m'\n",
    "\n",
    "movies_filename = 'movies.dat'\n",
    "users_filename = 'users.dat'\n",
    "ratings_filename = 'ratings.dat'\n",
    "\n",
    "movies_columns = ['MovieID', 'Title', 'Genres']\n",
    "users_columns = ['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']\n",
    "ratings_columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "\n",
    "def create_dataframe(data_dir, filename, columns):\n",
    "    data_file = os.path.join(data_dir, filename)\n",
    "    return pd.read_csv(data_file, delimiter='::', names=columns, encoding='latin-1', engine='python')\n",
    "\n",
    "movies = create_dataframe(data_dir, movies_filename, movies_columns)\n",
    "users = create_dataframe(data_dir, users_filename, users_columns)\n",
    "ratings = create_dataframe(data_dir, ratings_filename, ratings_columns)\n",
    "data = (users, movies, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d0150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_error(test_set, model, subset:int=None):\n",
    "    if subset is not None:\n",
    "        actual_ratings = test_set[:subset]['Rating']\n",
    "        predicted_ratings = test_set[:subset].apply(model, axis=1)\n",
    "    else:\n",
    "        actual_ratings = test_set['Rating']\n",
    "        predicted_ratings = test_set.apply(model, axis=1)\n",
    "\n",
    "    rating_error = ((actual_ratings - predicted_ratings)**2).mean()**(1/2)\n",
    "    return rating_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall mean rating \n",
    "mean_rating = ratings['Rating'].mean()\n",
    "\n",
    "# Lookup tables for naive models 2, 3, 4 and 5\n",
    "mean_rating_per_user = {user_id : ratings[ratings['UserID'] == user_id]['Rating'].mean() for user_id in users['UserID']}\n",
    "mean_rating_per_movie = {movie_id : ratings[ratings['MovieID'] == movie_id]['Rating'].mean() for movie_id in movies['MovieID']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af559708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_1(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors = np.array([])\n",
    "        \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        mean_rating = train_set['Rating'].mean()\n",
    "        \n",
    "        def model(row):\n",
    "            return mean_rating\n",
    "        \n",
    "        rating_err = rating_error(test_set, model, subset)\n",
    "        print(rating_err)\n",
    "        \n",
    "        rating_errors = np.append(rating_errors, rating_err)\n",
    "    return rating_errors\n",
    "\n",
    "errors = test_naive_model_1(data)\n",
    "mean_error = np.mean(errors)\n",
    "print('mean error', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_2(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors = np.array([])\n",
    "        \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        user_ids = train_set['UserID']\n",
    "        mean_rating_per_user = {user_id : train_set[train_set['UserID'] == user_id]['Rating'].mean() for user_id in users['UserID']}\n",
    "        \n",
    "        def model(row):\n",
    "            user_id = row['UserID']\n",
    "            return mean_rating_per_user[user_id]\n",
    "        \n",
    "        rating_err = rating_error(test_set, model, subset)\n",
    "        print(rating_err)\n",
    "        \n",
    "        rating_errors = np.append(rating_errors, rating_err)\n",
    "    return rating_errors\n",
    "\n",
    "errors = test_naive_model_3(data)\n",
    "mean_error = np.mean(errors)\n",
    "print('mean error', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_3(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors = np.array([])\n",
    "        \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        movie_ids = train_set['MovieID']\n",
    "        mean_rating_per_movie = {movie_id : train_set[train_set['MovieID'] == movie_id]['Rating'].mean() for movie_id in movies['MovieID']}\n",
    "        \n",
    "        def model(row):\n",
    "            movie_id = row['MovieID']\n",
    "            return mean_rating_per_movie[movie_id]\n",
    "        \n",
    "        rating_err = rating_error(test_set, model, subset)\n",
    "        print(rating_err)\n",
    "        \n",
    "        rating_errors = np.append(rating_errors, rating_err)\n",
    "    return rating_errors\n",
    "\n",
    "errors = test_naive_model_2(data)\n",
    "mean_error = np.mean(errors)\n",
    "print('mean error', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b856dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_error_4_5(test_set,reg):\n",
    "    \n",
    "    mean_rating_per_movie_list = np.array([mean_rating_per_movie[movie_id] for movie_id in test_set['MovieID']])\n",
    "    mean_rating_per_user_list = np.array([mean_rating_per_user[user_id] for user_id in test_set['UserID']])\n",
    "    \n",
    "    ##the predicted rating value for the test set using model 4 and 5.\n",
    "    mean_rating_list = np.vstack((mean_rating_per_movie_list,mean_rating_per_user_list)).T\n",
    "    pre_rating = reg.predict(mean_rating_list)[0]\n",
    "    \n",
    "    rating_error = ((test_set['Rating'] - pre_rating)**2).mean()**(1/2)\n",
    "    \n",
    "    return rating_error\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_model_4_5(data, subset:int=None):\n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    rating_errors_4 = np.array([])\n",
    "    rating_errors_5 = np.array([])\n",
    "    \n",
    "        \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        train_set = ratings.iloc[train_index]\n",
    "        test_set = ratings.iloc[test_index]\n",
    "        user_ids = train_set['UserID']\n",
    "        \n",
    "        mean_rating_per_movie = {movie_id : train_set[train_set['MovieID'] == movie_id]['Rating'].mean() for movie_id in movies['MovieID']}\n",
    "        mean_rating_per_user = {user_id : train_set[train_set['UserID'] == user_id]['Rating'].mean() for user_id in users['UserID']}\n",
    "        \n",
    "        \n",
    "        ##the lists of mean Ritem and mean Ruser for each rating in the train_set\n",
    "        mean_rating_per_movie_list = np.array([mean_rating_per_movie[movie_id] for movie_id in train_set['MovieID']])\n",
    "        mean_rating_per_user_list = np.array([mean_rating_per_user[user_id] for user_id in train_set['UserID']])\n",
    "        \n",
    "        ## stack the Ritem and Ruser lists for linear fitting\n",
    "        mean_rating_list = np.vstack((mean_rating_per_movie_list, mean_rating_per_user_list)).T\n",
    "        \n",
    "        print(mean_rating_list)\n",
    "        \n",
    "        ## uisng Ordinary least squares Linear Regression to find alpha beta and gamma\n",
    "        reg_4 = LinearRegression(fit_intercept=False).fit(mean_rating_list, train_set['Rating'])\n",
    "        reg_5 = LinearRegression(fit_intercept=True).fit(mean_rating_list, train_set['Rating'])\n",
    "\n",
    "        \n",
    "        rating_err_4 = test_error_4_5(test_set,reg_4)\n",
    "        rating_err_5 = test_error_4_5(test_set,reg_5)\n",
    "        \n",
    "        rating_errors_4 = np.append(rating_errors_4,rating_err_4)\n",
    "        rating_errors_5 = np.append(rating_errors_5,rating_err_5)\n",
    "        \n",
    "        print('Rating Error for Naive Model 4:', rating_err_4)\n",
    "        print('Rating Error for Naive Model 5:', rating_err_5)\n",
    "    \n",
    "    print('Mean Rating Error for Naive Model 4:', np.mean(rating_errors_4))   \n",
    "    print('Mean Rating Error for Naive Model 5:', np.mean(rating_errors_5))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_naive_model_4_5(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65910252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize...\n",
      "Start training\n",
      "err  0\n",
      "U  251.73490994547748\n",
      "M  38.647817776969674\n",
      "step  0\n",
      "err  0\n",
      "U  294.95106820138153\n",
      "M  122.022250462062\n",
      "step  1\n",
      "err  0\n",
      "U  132.25786248585342\n",
      "M  -79.56666753914608\n",
      "step  2\n",
      "err  0\n",
      "U  38422.43663254599\n",
      "M  -1475867.0709991432\n",
      "step  3\n",
      "err  0\n",
      "U  -1.635863056642872e+56\n",
      "M  -2.9123131506668236e+64\n",
      "step  4\n",
      "err  0\n",
      "U  nan\n",
      "M  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_766/3708634518.py:53: RuntimeWarning: overflow encountered in multiply\n",
      "  M[:, m] += learning_rate * (2 * err * old_U - lam * M[:, m])\n",
      "/tmp/ipykernel_766/3708634518.py:52: RuntimeWarning: overflow encountered in multiply\n",
      "  U[u, :] += learning_rate * (2 * err * M[:, m] - lam * U[u, :])\n",
      "/tmp/ipykernel_766/3708634518.py:52: RuntimeWarning: invalid value encountered in add\n",
      "  U[u, :] += learning_rate * (2 * err * M[:, m] - lam * U[u, :])\n",
      "/tmp/ipykernel_766/3708634518.py:52: RuntimeWarning: invalid value encountered in subtract\n",
      "  U[u, :] += learning_rate * (2 * err * M[:, m] - lam * U[u, :])\n",
      "/tmp/ipykernel_766/3708634518.py:53: RuntimeWarning: invalid value encountered in subtract\n",
      "  M[:, m] += learning_rate * (2 * err * old_U - lam * M[:, m])\n",
      "/tmp/ipykernel_766/3708634518.py:59: RuntimeWarning: overflow encountered in matmul\n",
      "  predicted_ratings = np.matmul(U, M)\n",
      "/tmp/ipykernel_766/3708634518.py:59: RuntimeWarning: invalid value encountered in matmul\n",
      "  predicted_ratings = np.matmul(U, M)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  5\n",
      "err  943\n",
      "U  nan\n",
      "M  nan\n",
      "step  6\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  7\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  8\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  9\n",
      "nan\n",
      "Start training\n",
      "err  0\n",
      "U  -143.1358772402784\n",
      "M  179.92959352939587\n",
      "step  0\n",
      "err  0\n",
      "U  -145.33465722905763\n",
      "M  163.38313536426875\n",
      "step  1\n",
      "err  0\n",
      "U  -127.96975475440294\n",
      "M  189.74317726044038\n",
      "step  2\n",
      "err  0\n",
      "U  -1094.3521945591954\n",
      "M  27233.74985674076\n",
      "step  3\n",
      "err  0\n",
      "U  1.5595243815315943e+23\n",
      "M  9.996053749789001e+28\n",
      "step  4\n",
      "err  0\n",
      "U  nan\n",
      "M  nan\n",
      "step  5\n",
      "err  718\n",
      "U  nan\n",
      "M  nan\n",
      "step  6\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  7\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  8\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  9\n",
      "nan\n",
      "Start training\n",
      "err  0\n",
      "U  131.23444756145355\n",
      "M  173.58600371573394\n",
      "step  0\n",
      "err  0\n",
      "U  136.99288694361087\n",
      "M  165.63725060283537\n",
      "step  1\n",
      "err  0\n",
      "U  129.62947222877276\n",
      "M  467.5635254556637\n",
      "step  2\n",
      "err  0\n",
      "U  -83750.91736954218\n",
      "M  115449964.8093107\n",
      "step  3\n",
      "err  0\n",
      "U  1.6776137212782143e+103\n",
      "M  6.087282920089167e+111\n",
      "step  4\n",
      "err  0\n",
      "U  nan\n",
      "M  nan\n",
      "step  5\n",
      "err  990\n",
      "U  nan\n",
      "M  nan\n",
      "step  6\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  7\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  8\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  9\n",
      "nan\n",
      "Start training\n",
      "err  0\n",
      "U  41.63180554461779\n",
      "M  -78.69719970735443\n",
      "step  0\n",
      "err  0\n",
      "U  51.43797255257029\n",
      "M  -99.14061519346932\n",
      "step  1\n",
      "err  0\n",
      "U  27.711891994628886\n",
      "M  -176.48854477332168\n",
      "step  2\n",
      "err  0\n",
      "U  3031.0573719116906\n",
      "M  -269138.92912280175\n",
      "step  3\n",
      "err  0\n",
      "U  -4.744444084660245e+38\n",
      "M  -4.115428767675201e+46\n",
      "step  4\n",
      "err  0\n",
      "U  nan\n",
      "M  nan\n",
      "step  5\n",
      "err  919\n",
      "U  nan\n",
      "M  nan\n",
      "step  6\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  7\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  8\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  9\n",
      "nan\n",
      "Start training\n",
      "err  0\n",
      "U  -72.5364612726807\n",
      "M  17.023370177995567\n",
      "step  0\n",
      "err  0\n",
      "U  -87.35096589049544\n",
      "M  -28.321601264855055\n",
      "step  1\n",
      "err  0\n",
      "U  -51.05377550291056\n",
      "M  82.63841365427794\n",
      "step  2\n",
      "err  0\n",
      "U  -826.4814430652523\n",
      "M  21503.2542713863\n",
      "step  3\n",
      "err  0\n",
      "U  1.5644085855990714e+16\n",
      "M  2.2429394514479305e+21\n",
      "step  4\n",
      "err  0\n",
      "U  nan\n",
      "M  nan\n",
      "step  5\n",
      "err  481\n",
      "U  nan\n",
      "M  nan\n",
      "step  6\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  7\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  8\n",
      "err  1000\n",
      "U  nan\n",
      "M  nan\n",
      "step  9\n",
      "nan\n",
      "mean error nan\n"
     ]
    }
   ],
   "source": [
    "def test_matrix_factorization(data, subset:int=None):\n",
    "    factors = 10\n",
    "    learning_rate = 0.005\n",
    "    n_training_steps = 10\n",
    "    lam = 0.05\n",
    "    \n",
    "    users, movies, ratings = data\n",
    "    \n",
    "    n_users = len(users)\n",
    "    n_movies = len(movies)\n",
    "    \n",
    "    rating_errors = np.array([])\n",
    "    \n",
    "    cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    indices = np.arange(1, n_movies + 1)\n",
    "    movie_ids = movies['MovieID'].values\n",
    "    shifted_indices = np.array([], dtype=np.int32)\n",
    "    counter = 0\n",
    "    for i in indices:\n",
    "        if movie_ids[i - 1] == i + counter:\n",
    "            shifted_indices = np.append(shifted_indices, i)\n",
    "        else:\n",
    "            shifted_indices = np.append(shifted_indices, 0)\n",
    "            shifted_indices = np.append(shifted_indices, i)\n",
    "            counter += 1\n",
    "            \n",
    "    print('Initialize...')\n",
    "    \n",
    "    for train_index, test_index in cv.split(ratings):\n",
    "        U = np.random.normal(0, 1, (n_users, factors))\n",
    "        M = np.random.normal(0, 1, (factors, n_movies))\n",
    "\n",
    "        predicted_ratings = np.matmul(U, M)\n",
    "\n",
    "        train_set = ratings.iloc[train_index[:1000]]\n",
    "        test_set = ratings.iloc[test_index[:1000]]\n",
    "        \n",
    "        user_indices = train_set['UserID'].values - 1\n",
    "        movie_indices = train_set['MovieID'].values - 1\n",
    "        movie_indices = shifted_indices[movie_indices] - 1\n",
    "        \n",
    "        print('Start training')\n",
    "        \n",
    "        for step in range(n_training_steps):\n",
    "            train_set_predicted_ratings = predicted_ratings[user_indices, movie_indices]\n",
    "            rating_errs = (train_set['Rating'] - train_set_predicted_ratings)\n",
    "            print('err ', np.sum(np.isnan(rating_errs).astype(np.int32)))\n",
    "            \n",
    "            for u, m, err in zip(user_indices, movie_indices, rating_errs):\n",
    "                old_U = U[u, :]\n",
    "                U[u, :] += learning_rate * (2 * err * M[:, m] - lam * U[u, :])\n",
    "                M[:, m] += learning_rate * (2 * err * old_U - lam * M[:, m])\n",
    "                \n",
    "            print('U ', np.sum(U))\n",
    "            print('M ', np.sum(M))\n",
    "\n",
    "            \n",
    "            predicted_ratings = np.matmul(U, M)\n",
    "            print('step ', step)\n",
    "        \n",
    "        test_set_predicted_ratings = predicted_ratings[user_indices, movie_indices]\n",
    "        test_rmse = ((test_set['Rating'] - test_set_predicted_ratings)**2).mean()**(1/2)\n",
    "\n",
    "        print(test_rmse)\n",
    "        \n",
    "        rating_errors = np.append(rating_errors, test_rmse)\n",
    "    return rating_errors\n",
    "\n",
    "errors = test_matrix_factorization(data)\n",
    "mean_error = np.mean(errors)\n",
    "print('mean error', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8925fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "\n",
    "c = np.vstack((a,b)).T\n",
    "\n",
    "print(c[0, 1])\n",
    "\n",
    "c[1][0] += 1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reg_4.coef_, reg_4.intercept_)\n",
    "# print(reg_5.coef_, reg_5.intercept_)\n",
    "\n",
    "# fig = plt.figure(figsize = (8, 8))\n",
    "# ax = plt.axes(projection =\"3d\")\n",
    "# ax.scatter3D(mean_rating_per_movie_list, train_set['Rating'], mean_rating_per_user_list, c=train_set['Rating'], s=0.01)\n",
    "# x = np.linspace(3.0, 4.0, 100)\n",
    "# y = np.linspace(0.0, 5.0, 10)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "# ax.scatter3D(X, Y, reg_4.coef_[0] * X + reg_4.coef_[1] * Y + reg_4.intercept_, s=0.1)\n",
    "# ax.scatter3D(X, Y, reg_5.coef_[1] * X + reg_5.coef_[0] * Y + reg_5.intercept_, s=1.0)\n",
    "# ax.view_init(0, -190)\n",
    "# plt.show()\n",
    "\n",
    "# x = np.linspace(0.0, 5.0, 100)\n",
    "# e = np.random.normal(0, 0.5, 100)\n",
    "# y = 0.7 * x - 0.3\n",
    "\n",
    "x = np.array([])\n",
    "y = np.array([])\n",
    "\n",
    "for i in np.arange(5):\n",
    "    x = np.concatenate((x, np.random.normal(1.0 + i * 0.5, 1.0, 100)))\n",
    "    y = np.concatenate((y, i * np.ones(100)))\n",
    "\n",
    "lin_reg = LinearRegression(fit_intercept=True).fit(x[..., None], y)\n",
    "\n",
    "a = lin_reg.coef_[0]\n",
    "b = lin_reg.intercept_\n",
    "\n",
    "print(lin_reg.coef_)\n",
    "print(lin_reg.intercept_)\n",
    "print(lin_reg.score(x[..., None], y))\n",
    "\n",
    "plt.plot(np.linspace(0, 5, 100), a * np.linspace(0, 5, 100) + b)\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
